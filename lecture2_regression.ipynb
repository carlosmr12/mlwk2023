{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06a6d3d-7ff8-4c43-ba4f-6b373e180cb7",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop - Exploring small molecule potency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599429a-e87f-4fe1-bd9c-73938e345571",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Task Overview\n",
    "- Data Exploring\n",
    "- Supervised Learning\n",
    "    - ~~Classification (Less-potent vs Potent PPI inhibitors)~~ (Lecture 1 - Alex de Sá)\n",
    "    - Regression (PPI inhibitory potency)\n",
    "        - Decision Tree\n",
    "        - Performance Evaluation\n",
    "        - Random Forest - Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a7988-9ccb-40bb-983e-c0a094e42694",
   "metadata": {},
   "source": [
    "### Task Overview\n",
    "The problem we will solve is **predicting inhibitory activity of small molecules against certain protein-protein interactions (PPIs)**. \n",
    "\n",
    "Proteins rarely act alone as their functions tend to be regulated. Many molecular processes within a cell are dependents of PPIs. Some PPIs are involved in multiple aggregation-related diseases, such as Creutzfeldt–Jakob and Alzheimer's diseases. The discovery of novel molecules capable of inhibiting these processes can be of great importance for medicine.\n",
    "\n",
    "Small molecules are low molecular weight molecules that include lipids, monosaccharides, second messengers, other natural products and metabolites, as well as drugs and other xenobiotics. They can interact with receptors and regulate biological processes. \n",
    "\n",
    "The first thing we need is a data set with inhibitory activity values for real molecules. For this workshop, we will use datasets from [TIMBAL](https://pubmed.ncbi.nlm.nih.gov/23766369/) and [iPPIDB](https://pubmed.ncbi.nlm.nih.gov/33416858/). \n",
    "\n",
    "The inhibitory activity values are reported in **-log(IC50)**. IC50 means how much of a particular inhibitory drug is needed to inhibit a given biological process or biological component by 50\\%. It is measured in uM (micromolar).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b66fe-11d7-4653-a190-939f2afc8ea3",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75fe54-e9fc-4a54-86a3-29c0b02864d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from plotly.subplots import make_subplots\n",
    "from rdkit.Chem.Draw import IPythonConsole #RDKit drawing\n",
    "# A few settings to improve the quality of structures \n",
    "from rdkit.Chem import rdDepictor\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "rdDepictor.SetPreferCoordGen(True)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "from math import sqrt\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import pearsonr, kendalltau, spearmanr\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035567e-6a89-45af-a1d8-eff0c9c6a989",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b3ecc-cab6-426b-8155-774976789ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/carlosmr12/mlwk2023/master/data/ppi_inhibitors.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788f444-cc9f-4566-9873-40af2bd78777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"ppi_inhibitors.csv\") # Load data from file to a DataFrame structure\n",
    "print(df_data.shape) # .shape displays how the dataframe (matrix) looks like\n",
    "df_data.head() # .head() displays the first few items in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fe1bd-0b6d-4bbf-88f4-e308455c9acf",
   "metadata": {},
   "source": [
    "Data distribution based on data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11720a4-58d9-4158-b4d0-a37d1fa616b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data['database'].value_counts())\n",
    "\n",
    "fig = px.pie(df_data, values=df_data['database'].value_counts().values, \\\n",
    "             names=df_data['database'].value_counts().index, \\\n",
    "             title='Data sources')\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906b03-4b50-4293-a4d3-7f32f1167132",
   "metadata": {},
   "source": [
    "The molecules of the dataset are represented through **SMILES**. SMILES is a chemical notation that allows representation of a chemical structure.  They can be represented using simple vocabulary (atom and bond symbols), and few grammar rules: \n",
    "\n",
    "- ***2-Propanol would be “CC(O)C”***\n",
    "\n",
    "- ***2-Methylbutanal would be “CC(C)CC(=O)”.***\n",
    "\n",
    "Using a type of SMILES called ISOMERIC SMILES it is even possible to represent specific isotopism, configuration about double bonds, and chirality. \n",
    "\n",
    "Below you can see some examples of SMILES in our data:\n",
    "\n",
    "\n",
    "2D depiction of small molecules based on the SMILES format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2bef9-726c-468a-8435-fa5ea5e49cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.iloc[0]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[0]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed08c42-42ba-439c-b884-105fc0968933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.iloc[-1]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[-1]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c450f7-b4c1-4b03-a053-1bd2bc9cc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.iloc[1]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[2]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf2bc5-aa0c-470d-853e-b37ec29129f6",
   "metadata": {},
   "source": [
    "What does the distribution of our target variable look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c53b6-6912-44b0-a1bd-412351ea2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Experimental IC50 (log10)\"\n",
    "fig = px.histogram(df_data, x=target)\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f142ddc-9872-47e3-9183-fd4de344e07d",
   "metadata": {},
   "source": [
    "Why do we would preferably work with the target variable in a log scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9dd25b-2219-4a47-a917-9ba65224feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['inverse_log'] = 10**df_data[target]\n",
    "fig = px.histogram(df_data, x='inverse_log')\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1860fe6-d337-4130-be99-e18d4cd21cda",
   "metadata": {},
   "source": [
    "It is also important to note that ours datasets covers, besides a long range of concentrations, also a range of values for diferent properties. This is also important to generate more generalised  models.\n",
    "\n",
    "An important concept here is **feature**. A feature is a property of the object you’re trying to predict. It can also be referred to as indepent variable, since it is a fixed property of the data point and it does not depend of others variables. These independent variables are essential, because the algorithms need characteristics of the data points as support for the learning process and predicting the labels (in our case inhibitory activity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b86a8-8c08-4e3f-bc17-d5ca0fc7d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"MolLogP\", \"Acceptor_Count\", \"Donor_Count\", \"NumRotatableBonds\",\n",
    "           \"RingCount\", \"MolWt\"]\n",
    "\n",
    "fig = make_subplots(rows=3, cols=2, start_cell=\"bottom-left\")\n",
    "\n",
    "nlines = 3\n",
    "ncolumns = 2\n",
    "\n",
    "for i in range(nlines):\n",
    "    for j in range(ncolumns):\n",
    "        fig.add_trace(go.Histogram(x=df_data[columns[i+j]], name=columns[i+j]), row=i+1, col=j+1)\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8a97-0380-4be3-83a1-46cdb209c5fc",
   "metadata": {},
   "source": [
    "### Regression (PPI inhibitory potency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8dac3-d93f-4d44-bd44-1df5f2b55cd4",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1005d-5fa4-4bd9-af20-5f6b185c0e18",
   "metadata": {},
   "source": [
    "The method **train_test_split()** used in the code below divides our data into two subsets: \n",
    "\n",
    "- One subset to *train* the model\n",
    "- A subset to evaluate or *test* how good your model is, which should\n",
    "    - Be large enough to yield statistically meaningful results\n",
    "    - Be representative of the data set as whole\n",
    "\n",
    "*(Never train on test data)*\n",
    "\n",
    "Splitting your dataset into training and test sets is very important and it is directly related to your models ability to *learn* patterns during the training step, which will ideally help to make it generalisable. Using the test set (a subset completely unseen during trainning) you can estimate the performance of the model when it is applied to new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d7ab0-5ea7-45af-b3e2-8079c4116bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Experimental IC50 (log10)\"\n",
    "\n",
    "# Basic properties\n",
    "basic_properties = [\"MolLogP\", \"Acceptor_Count\", \"Donor_Count\", \"NumRotatableBonds\",\n",
    "                    \"RingCount\", \"MolWt\"]\n",
    "\n",
    "# What is the best TEST_SIZE?\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X = df_data[basic_properties]\n",
    "y = df_data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train_fpr = df_data.iloc[X_train.index].drop([\"Experimental IC50 (log10)\", \"SMILES\", \"database\"], axis=1)\n",
    "X_test_fpr = df_data.iloc[X_test.index].drop([\"Experimental IC50 (log10)\", \"SMILES\", \"database\"], axis=1)\n",
    "y_train_fpr = df_data.iloc[X_train.index][target]\n",
    "y_test_fpr = df_data.iloc[X_test.index][target]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, start_cell=\"bottom-left\")\n",
    "\n",
    "fig.add_trace(go.Histogram(x=y_train, name='Training set'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=y_test, name='Test set'), row=1, col=2)\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd5116-6eb9-4c08-93ab-70cf8b825b21",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a4b99-df34-46a5-a0eb-2194ab2b5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "y_pred_train = cross_val_predict(regressor, X_train, y_train, cv=5)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "\n",
    "rmse_train = round(sqrt(mean_squared_error(y_train, y_pred_train)), 2)\n",
    "pearsons_train = round(pearsonr(y_train, y_pred_train)[0], 2)\n",
    "kendalls_train = round(kendalltau(y_train, y_pred_train)[0], 2)\n",
    "spearmans_train = round(spearmanr(y_train, y_pred_train)[0], 2)\n",
    "rmse_test = round(sqrt(mean_squared_error(y_test, y_pred_test)), 2)\n",
    "pearsons_test = round(pearsonr(y_test, y_pred_test)[0], 2)\n",
    "kendalls_test = round(kendalltau(y_test, y_pred_test)[0], 2)\n",
    "spearmans_test = round(spearmanr(y_test, y_pred_test)[0], 2)\n",
    "\n",
    "d = [ [\"RMSE\", rmse_train, rmse_test],\n",
    "     [\"Pearson's\", pearsons_train, pearsons_test],\n",
    "     [\"Kendall's\", kendalls_train, kendalls_test],\n",
    "     [\"Spearman's\", spearmans_train, spearmans_test]]\n",
    "\n",
    "print(tabulate(d, headers=[\"Metric\", \"Training\", \"Test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a59eed-18d4-4b77-af86-c4cd59c43ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, start_cell=\"bottom-left\")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_train, y=y_pred_train, name='Training set', \n",
    "                         mode=\"markers\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=y_test, y=y_pred_test, name='Test set', \n",
    "                         mode=\"markers\"), row=1, col=2)\n",
    "\n",
    "x = sm.add_constant(y_train)\n",
    "p = sm.OLS(y_pred_train, x).fit().params\n",
    "x = np.arange(y_train.min(), y_train.max())\n",
    "y = p.const + p[target] * x\n",
    "fig.add_trace(go.Scatter(x=x, y=y, name='', mode=\"lines\", \n",
    "                         line=dict(dash='dash', color=\"black\"), \n",
    "                         showlegend=False), row=1, col=1)\n",
    "\n",
    "x = sm.add_constant(y_test)\n",
    "p = sm.OLS(y_pred_test, x).fit().params\n",
    "x = np.arange(y_test.min(), y_test.max())\n",
    "y = p.const + p[target] * x\n",
    "fig.add_trace(go.Scatter(x=x, y=y, name='', mode=\"lines\", \n",
    "                         line=dict(dash='dash', color=\"black\"), \n",
    "                         showlegend=False), row=1, col=2)\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5997b-ad0f-4e27-9575-7edcda3f39e3",
   "metadata": {},
   "source": [
    "Which feature is more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff6808-33a3-40ce-83a5-f28b0f6a48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "scores = []\n",
    "try:\n",
    "    for feature,score in zip(regressor.feature_names_in_, regressor.feature_importances_):\n",
    "        if score != 0:\n",
    "            labels.append(feature)\n",
    "            scores.append(round(score,2))\n",
    "except AttributeError as e:\n",
    "    for feature,score in zip(range(0, len(regressor.feature_importances_)), regressor.feature_importances_):\n",
    "        if score != 0:\n",
    "            labels.append(feature)\n",
    "            scores.append(round(score,2))\n",
    "fig = px.bar(x=labels, y=scores, title=\"Feature importance\")\n",
    "fig.update_layout(yaxis_title=\"Importance score\", xaxis_title=\"Features\")\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490898c-148c-4448-835d-878f099d84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1 ,ncols=1, figsize=(9,6), dpi=300)\n",
    "tree.plot_tree(regressor, feature_names=X_train.columns.tolist(), filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2c4c3-9c6b-4357-a474-31b0a94e11d9",
   "metadata": {},
   "source": [
    "#### Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf5425-c38a-4ec6-85aa-ec2b41333b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b58198-e8ae-4b83-a6da-4da7d462cefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b13a58-1908-448e-9f7f-d52e74c7b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4fe541-a420-496a-8184-5a8eb03cd977",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242bbe1d-751a-43a0-a486-e5b437792452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
