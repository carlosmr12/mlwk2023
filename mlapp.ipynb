{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/carlosmr12/mlwk2023/blob/master/mlapp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop - Exploring small molecule data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing this material\n",
    "\n",
    "All material used in this workshop can be downloaded at **[https://github.com/carlosmr12/mlwk2023](https://github.com/carlosmr12/mlwk2023)**.\n",
    "\n",
    "Instructions for installation are detailed in the *README.md* file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Task Overview\n",
    "- Data Exploring\n",
    "- Unsupervised Learning\n",
    "- Supervised Learning\n",
    "    - Classification (Less-potent vs Potent PPI inhibitors)\n",
    "    - Regression (PPI inhibitory potency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we will solve is **predicting inhibitory activity of small molecules against certain protein-protein interactions (PPIs)**. \n",
    "\n",
    "Proteins rarely act alone as their functions tend to be regulated. Many molecular processes within a cell are dependents of PPIs. Some PPIs are involved in multiple aggregation-related diseases, such as Creutzfeldt–Jakob and Alzheimer's diseases. The discovery of novel molecules capable of inhibiting these processes can be of great importance for medicine.\n",
    "\n",
    "Small molecules are low molecular weight molecules that include lipids, monosaccharides, second messengers, other natural products and metabolites, as well as drugs and other xenobiotics. They can interact with receptors and regulate biological processes. \n",
    "\n",
    "The first thing we need is a data set with inhibitory activity values for real molecules. For this workshop, we will use datasets from [TIMBAL](https://pubmed.ncbi.nlm.nih.gov/23766369/) and [iPPIDB](https://pubmed.ncbi.nlm.nih.gov/33416858/). \n",
    "\n",
    "The inhibitory activity values are reported in **-log(IC50)**. IC50 means how much of a particular inhibitory drug is needed to inhibit a given biological process or biological component by 50\\%. It is measured in uM (micromolar).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data and requirements files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/carlosmr12/mlwk2023/master/data/ppi_inhibitors.minified.csv\n",
    "!wget https://raw.githubusercontent.com/carlosmr12/mlwk2023/master/requirements.txt\n",
    "!wget https://raw.githubusercontent.com/carlosmr12/mlwk2023/master/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmpcOpqDZjWF",
    "outputId": "6c5ce055-3f3c-448a-c0e7-e4c39d574163"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQ9flrTHaIEb",
    "outputId": "e546b5cd-d687-401b-d278-e3a043255bb8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from plotly.subplots import make_subplots\n",
    "from rdkit.Chem.Draw import IPythonConsole #RDKit drawing\n",
    "# A few settings to improve the quality of structures \n",
    "from rdkit.Chem import rdDepictor\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "rdDepictor.SetPreferCoordGen(True)\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "6IMnadvDatyN",
    "outputId": "c5701f6e-5213-4def-d5f6-7d05ece1ac3a"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"ppi_inhibitors.minified.csv\") # Load data from file to a DataFrame structure\n",
    "print(df_data.shape) # .shape displays how the dataframe (matrix) looks like\n",
    "df_data.head() # .head() displays the first few items in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "5OkunBhib-G6",
    "outputId": "f15352c8-24db-4610-ec20-3e3b767d742f"
   },
   "outputs": [],
   "source": [
    "print(df_data['database'].value_counts())\n",
    "\n",
    "fig = px.pie(df_data, values=df_data['database'].value_counts().values, \\\n",
    "             names=df_data['database'].value_counts().index, \\\n",
    "             title='Data sources')\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "P_k_WsFgcIg1",
    "outputId": "9161b9b8-5c84-4a49-f0c3-ab675cace208"
   },
   "outputs": [],
   "source": [
    "target = \"Experimental IC50 (log10)\"\n",
    "fig = px.histogram(df_data, x=target)\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the experimental values (IC50) were logarithmized. This conversion is necessary for normalising the targets for the machine learning models, so they can learn better the patterns between input molecules and targets, aiming to provide a better generalisation performance. It is also important to note that ours datasets covers a long range of concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "E3P_qZGdcoZs",
    "outputId": "1cdefa72-5fe6-448a-bdb4-05b2d9104f29"
   },
   "outputs": [],
   "source": [
    "columns = [\"MolLogP\", \"Acceptor_Count\", \"Donor_Count\", \"NumRotatableBonds\", \\\n",
    "           \"RingCount\", \"MolWt\"]\n",
    "\n",
    "fig = make_subplots(rows=3, cols=2, start_cell=\"bottom-left\")\n",
    "\n",
    "nlines = 3\n",
    "ncolumns = 2\n",
    "\n",
    "for i in range(nlines):\n",
    "    for j in range(ncolumns):\n",
    "        fig.add_trace(go.Histogram(x=df_data[columns[i+j]], name=columns[i+j]), row=i+1, col=j+1)\n",
    "\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also important to note that ours datasets covers, besides a long range of concentrations, also a range of values for diferent properties. This is also important to generate more generalized  models.\n",
    "\n",
    "An important concept here is **feature**. A feature is a property of the object you’re trying to predict. It can also be referred to as indepent variable, since it is a fixed property of the data point and it does not depend of others variables. These independent variables are essential, because the algorithms need characteristics of the data points as support for the learning process and predicting the labels (in our case inhibitory activity). \n",
    "\n",
    "The molecules of the dataset are represented through **SMILES**. SMILES is a chemical notation that allows representation of a chemical structure.  They can be represented using simple vocabulary (atom and bond symbols), and few grammar rules: \n",
    "\n",
    "- ***2-Propanol would be “CC(O)C”***\n",
    "\n",
    "- ***2-Methylbutanal would be “CC(C)CC(=O)”.***\n",
    "\n",
    "Using a type of SMILES called ISOMERIC SMILES it is even possible to represent specific isotopism, configuration about double bonds, and chirality. \n",
    "\n",
    "Below you can see some examples of SMILES in our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8L1upGIcu2T",
    "outputId": "91bd5137-e1d7-4143-a02f-defc2e25ab9f"
   },
   "outputs": [],
   "source": [
    "print(df_data.iloc[0]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[0]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.iloc[1]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[1]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.iloc[2]['SMILES'])\n",
    "m = Chem.MolFromSmiles(df_data.iloc[2]['SMILES'])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browse the [PubChem](https://pubchem.ncbi.nlm.nih.gov/) database for examples of small molecules and input them below to draw their 2D depiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_smiles = \"<PUT YOUR SMILES STRING HERE>\"\n",
    "m = Chem.MolFromSmiles(my_smiles)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to characterize the molecules of the dataset as **potent** or **less potent** we need to set a threshold value.\n",
    "\n",
    "Finding this value is not a simple task, it depends of the biological question. According to *Arkin et al, 2014* values **> 5** are considered favorable for in vivo activity. \n",
    "\n",
    "But you could select a threshold higher or lower in order to predict as positive only very potent small molecules or, vice-verse, respectively.  \n",
    "\n",
    "- *Arkin MR, Tang Y, Wells JA. Small-molecule inhibitors of protein-protein interactions: progressing toward the reality. Chem Biol. 2014 Sep 18;21(9):1102-14. DOI: 10.1016/j.chembiol.2014.09.001. PMID: 25237857*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the variable below to split the dataset into potent and less potent inhibitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUUEvN7rc0_5"
   },
   "outputs": [],
   "source": [
    "THRESHOLD_POTENCY = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['potency_class'] = 'less_potent'\n",
    "df_data.loc[df_data[target] > THRESHOLD_POTENCY, 'potency_class'] = 'potent'\n",
    "\n",
    "fig = px.pie(df_data, values=df_data['potency_class'].value_counts().values, \\\n",
    "             names=df_data['potency_class'].value_counts().index, \\\n",
    "             color=df_data['potency_class'].value_counts().index, \\\n",
    "             title='PPI inhibitors potency', \\\n",
    "             color_discrete_map={'less_potent':'blue', 'potent':'red'})\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional properties\n",
    "\n",
    "#### Fingerprints\n",
    "\n",
    "A **fingerprint** is a fixed length array, where different elements indicate the presence of different features in the molecule. If two molecules have similar fingerprints, that indicates they contain many of the same features, and therefore will likely have similar chemistry.\n",
    "\n",
    "The small molecules fingerprints can be derived from the SMILES.\n",
    "  \n",
    "#### Morgan Fingerprints (Circular Fingerprints)\n",
    "\n",
    "This family of fingerprints, better known as *circular fingerprints*, is built by applying the Morgan algorithm to a set of user-supplied atom invariants. When generating Morgan fingerprints, the radius of the fingerprint must also be provided.\n",
    "\n",
    "- *Rogers, D.; Hahn, M. “Extended-Connectivity Fingerprints.” J. Chem. Inf. and Model. 50:742-54 (2010). DOI: 10.1021/ci100050t. PMID: 20426451*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles(df_data.iloc[-1]['SMILES'])\n",
    "\n",
    "N_BITS = 128\n",
    "info = {}\n",
    "fpr = AllChem.GetMorganFingerprintAsBitVect(m, useChirality=True, radius=2, nBits=N_BITS, bitInfo=info)\n",
    "\n",
    "bits_fpr = list(info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[bits_fpr[0]])\n",
    "svg_img = Draw.DrawMorganBit(m, bits_fpr[0], info, useSVG=True)\n",
    "svg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[bits_fpr[5]])\n",
    "svg_img1 = Draw.DrawMorganBit(m, bits_fpr[5], info, useSVG=True)\n",
    "svg_img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[bits_fpr[7]])\n",
    "svg_img1 = Draw.DrawMorganBit(m, bits_fpr[7], info, useSVG=True)\n",
    "svg_img1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Fingerprints for all molecules in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BITS = 64\n",
    "fprs_data = []\n",
    "\n",
    "for s in df_data['SMILES']:\n",
    "    m = Chem.MolFromSmiles(s)\n",
    "    fpr = AllChem.GetMorganFingerprintAsBitVect(m, useChirality=True, radius=2, nBits=N_BITS)\n",
    "    fprs_data.append(np.array(fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fprs = pd.DataFrame(np.array(fprs_data))\n",
    "\n",
    "df_fprs['Experimental IC50 (log10)'] = df_data['Experimental IC50 (log10)']\n",
    "df_fprs['potency_class'] = df_data['potency_class']\n",
    "\n",
    "df_fprs.shape\n",
    "df_fprs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What possible issues could a \"binary matrix\" have in this case?\n",
    "\n",
    "- All zeros and all 1s columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\\t{}\".format(df_fprs.shape))\n",
    "X = df_fprs.drop(['Experimental IC50 (log10)', 'potency_class'], axis=1)\n",
    "# selector = VarianceThreshold(threshold=0) # remove the features that have the same value in all samples\n",
    "selector = VarianceThreshold(threshold=0.15)\n",
    "selector.fit(X)\n",
    "mask = selector.get_support()\n",
    "\n",
    "df_fprs = X.loc[:, mask].copy()\n",
    "df_fprs.loc[:, 'Experimental IC50 (log10)'] = df_data['Experimental IC50 (log10)']\n",
    "df_fprs.loc[:, 'potency_class'] = df_data['potency_class']\n",
    "print(\"After:\\t{}\".format(df_fprs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning (Classification)\n",
    "\n",
    "Your task here is to build a classifier to differentiate potent compounds from less potent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code below to select the select specific columns for the basic features (**df_data**) and fingerprints (**df_fprs**)) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'potency_class'\n",
    "\n",
    "# Basic features dataset\n",
    "features = [\"MolLogP\", \"Acceptor_Count\", \"Donor_Count\", \"NumRotatableBonds\", \\\n",
    "           \"RingCount\", \"MolWt\"]\n",
    "\n",
    "X = df_data[features]\n",
    "y = df_data[target]\n",
    "\n",
    "# What is the best TEST_SIZE?\n",
    "TEST_SIZE = 0.26\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, \\\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Selecting same train and test entries in the Fingerprints dataset\n",
    "X_train_fpr = df_fprs.iloc[X_train.index]\n",
    "X_train_fpr = X_train_fpr.loc[:,38:63] # Selecting only a specific set of features/columns using indexes\n",
    "X_test_fpr = df_fprs.iloc[X_test.index]\n",
    "X_test_fpr = X_test_fpr.loc[:,38:63] # It needs to be the equal to the X_train_fpr\n",
    "\n",
    "y_train_fpr = df_fprs.iloc[X_train.index][target]\n",
    "y_test_fpr = df_fprs.iloc[X_test.index][target]\n",
    "\n",
    "# print(y_train.value_counts())\n",
    "utils.plot_train_test_class(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is data splitting necessary?\n",
    "\n",
    "If you check in the code lines above you used a function \"train_test_split\". This function divided our data into two subsets. One part is used to evaluate or test the data and the other to train the model.\n",
    "\n",
    "This is step is very important because it helps ensure the creation of data models and processes that use data models are accurate. Using the the test set (a subset completely unseen during trainning) you can estimate the performance of the model when it is applied to new data points.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)\n",
    "\n",
    "SVM works by splitting the data using a hyperplane so that data points can be categorized, even when the data are not otherwise linearly separable.\n",
    "\n",
    "- *Cristianini N., Ricci E. (2008) Support Vector Machines. In: Kao MY. (eds) Encyclopedia of Algorithms. Springer, Boston, MA. DOI: 10.1007/978-0-387-30162-4_415*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "y_pred_train = cross_val_predict(clf, X_train, y_train, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Evaluation**\n",
    "\n",
    "Which metric (or metrics) should we consider when evaluating binary classifiers?\n",
    "\n",
    "What if the dataset is unbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_cm(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint-based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "y_pred_train_fpr = cross_val_predict(clf, X_train_fpr, y_train_fpr, cv=5)\n",
    "\n",
    "clf.fit(X_train_fpr, y_train_fpr)\n",
    "y_pred_test_fpr = clf.predict(X_test_fpr)\n",
    "\n",
    "utils.gen_train_test_cm(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "Decision trees are composed of if/else questions disposed in a hierarchical manner, following these questions the model is capable of reaching a decision. In the case of our question, the actual output are 'less_potent' or 'potent' labels. The decision to reach prediction is based on the features (graph based signatures and auxiliary features) we used as input for the ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "y_pred_train = cross_val_predict(clf, X_train, y_train, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "utils.gen_train_test_cm(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the decision tree looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1 ,ncols=1, figsize=(9,6), dpi=300)\n",
    "tree.plot_tree(clf, feature_names=X_train.columns, class_names=['less_potent', 'potent'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint-based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "y_pred_train_fpr = cross_val_predict(clf, X_train_fpr, y_train_fpr, cv=5)\n",
    "\n",
    "clf.fit(X_train_fpr, y_train_fpr)\n",
    "y_pred_test_fpr = clf.predict(X_test_fpr)\n",
    "\n",
    "utils.gen_train_test_cm(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the decision tree looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1 ,ncols=1, figsize=(9,6), dpi=300)\n",
    "tree.plot_tree(clf, feature_names=X_train_fpr.columns, class_names=['less_potent', 'potent'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTrees\n",
    "\n",
    "There are other algorithms as ExtraTrees that belong to the class of ensembles of decision trees. These methods combine multiple decision trees ML models to create more powerful models.\n",
    "\n",
    "ExtraTrees implements many decision trees, each one is different from the others. Each tree is capable of doing proper predictions, but tends to overfit on part of the data. When many trees are combined, overfitting will be reduced by averaging the tree results.\n",
    "\n",
    "- *Geurts, P., Ernst, D. & Wehenkel, L. Extremely randomized trees. Mach Learn 63, 3–42 (2006). DOI: 10.1007/s10994-006-6226-1*\n",
    "\n",
    "##### Training on the basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "y_pred_train = cross_val_predict(clf, X_train, y_train, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "utils.gen_train_test_cm(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train, y_pred_train, y_test, y_pred_test, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint-based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "y_pred_train_fpr = cross_val_predict(clf, X_train_fpr, y_train_fpr, cv=5)\n",
    "\n",
    "clf.fit(X_train_fpr, y_train_fpr)\n",
    "y_pred_test_fpr = clf.predict(X_test_fpr)\n",
    "\n",
    "utils.gen_train_test_cm(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.gen_train_test_roc(y_train_fpr, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, ['less_potent', 'potent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "What if we try to predict the actual IC50 values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Experimental IC50 (log10)\"\n",
    "\n",
    "# Basic properties\n",
    "basic_properties = [\"MolLogP\", \"Acceptor_Count\", \"Donor_Count\", \"NumRotatableBonds\", \\\n",
    "           \"RingCount\", \"MolWt\"]\n",
    "\n",
    "# What is the best TEST_SIZE?\n",
    "TEST_SIZE = 0.12\n",
    "\n",
    "X = df_data[basic_properties]\n",
    "y = df_data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, \\\n",
    "                                                   random_state=42)\n",
    "\n",
    "X_train_fpr = df_fprs.iloc[X_train.index].drop([\"Experimental IC50 (log10)\", \"potency_class\"], axis=1)\n",
    "X_test_fpr = df_fprs.iloc[X_test.index].drop([\"Experimental IC50 (log10)\", \"potency_class\"], axis=1)\n",
    "y_train_fpr = df_fprs.iloc[X_train.index][target]\n",
    "y_test_fpr = df_fprs.iloc[X_test.index][target]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, start_cell=\"bottom-left\")\n",
    "\n",
    "fig.add_trace(go.Histogram(x=y_train, name='Training set'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=y_test, name='Test set'), row=1, col=2)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM\n",
    "\n",
    "##### Training on the Basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel=\"rbf\")\n",
    "y_pred_train = cross_val_predict(regressor, X_train, y_train, cv=5)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train, y_test, y_pred_test)\n",
    "utils.plot_clf_performance(y_train, y_pred_train, y_test, y_pred_test, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel=\"rbf\")\n",
    "y_pred_train_fpr = cross_val_predict(regressor, X_train_fpr, y_train, cv=5)\n",
    "\n",
    "regressor.fit(X_train_fpr, y_train)\n",
    "y_pred_test_fpr = regressor.predict(X_test_fpr)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr)\n",
    "utils.plot_clf_performance(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "##### Training on the Basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "y_pred_train = cross_val_predict(regressor, X_train, y_train, cv=5)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train, y_test, y_pred_test)\n",
    "utils.plot_clf_performance(y_train, y_pred_train, y_test, y_pred_test, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "y_pred_train_fpr = cross_val_predict(regressor, X_train_fpr, y_train_fpr, cv=5)\n",
    "\n",
    "regressor.fit(X_train_fpr, y_train_fpr)\n",
    "y_pred_test_fpr = regressor.predict(X_test_fpr)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr)\n",
    "utils.plot_clf_performance(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesRegressor\n",
    "\n",
    "##### Training on the Basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "y_pred_train = cross_val_predict(regressor, X_train, y_train, cv=5)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train, y_test, y_pred_test)\n",
    "utils.plot_clf_performance(y_train, y_pred_train, y_test, y_pred_test, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on the Fingerprint based set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "y_pred_train_fpr = cross_val_predict(regressor, X_train_fpr, y_train_fpr, cv=5)\n",
    "\n",
    "regressor.fit(X_train_fpr, y_train_fpr)\n",
    "y_pred_test_fpr = regressor.predict(X_test_fpr)\n",
    "\n",
    "utils.regression_metrics(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr)\n",
    "utils.plot_clf_performance(y_train, y_pred_train_fpr, y_test_fpr, y_pred_test_fpr, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are more important for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feat_importance(regressor)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOH/idxCI1yAxG05pnpxM1M",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
